{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This script runs a simple glm on one subject for the MCSE condition\n",
    "and returns the contrasts obtained.\n",
    "\n",
    "This task (described in [https://doi.org/10.1523/JNEUROSCI.6048-11.2012]) was originally used to study whether visual search processes of a salient target can be thought as a purely bottom-up process, or if it requires action from top-down attentional processess. The task consisted in the presentation of an array of 35 “L” letters, rotated at different angles, together with a target “T” letter (total 36 stimuli in each trial). Subjects were instructed to search for the target and indicate whether it was on the left or right side of the grid, by pressing respectively with the index or middle finger on a 5-button response box. There were two conditions: high-salience (the target is gray while the other stimuli is black) and low-salience (all stimuli are gray).\n",
    "The two conditions were presented alternatively in blocks, with 6 blocks of 10 trials\n",
    "each. Each trial was presented for 3 s with an inter-stimulus interval of 1 s. There was\n",
    "also a 20 s fixation cross between blocks. Data was acquired in two separated runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent / \"scripts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is a grey matter mask, that defines which regions of the brain \n",
    "from nilearn.plotting import plot_roi\n",
    "gm_mask = 'data/gm_mask_3mm.nii.gz'\n",
    "plot_roi(gm_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is where the data can be found on the disk of my machine\n",
    "# Please update it to match where it can be found\n",
    "from download_data import download_data\n",
    "import os\n",
    "download_data()\n",
    "data_dir = 'data/3mm'\n",
    "subjects = [os.path.basename(x) for x in\n",
    "            glob.glob(os.path.join(data_dir, 'sub-*'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Time of repetition, i.e. time between consecutive scans\n",
    "import json\n",
    "TR = json.load(open('data/3mm/task-MCSE_dir-ap_bold.json'))['RepetitionTime']\n",
    "print(TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a results directory, where we will geenrate all ouputs for this session\n",
    "# Can be any valid paths on you disk\n",
    "write_dir = 'results'\n",
    "if not os.path.exists(write_dir):\n",
    "    os.mkdir(write_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is where the data can be found on the disk of my machine\n",
    "# Please update it to match where it can be found\n",
    "from download_data import download_data\n",
    "download_data()\n",
    "data_dir = 'data/3mm'\n",
    "subjects = [os.path.basename(x) for x in\n",
    "            glob.glob(os.path.join(data_dir, 'sub-*'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we define a utility function to fetch individual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_data(data_dir, subject):\n",
    "    \"\"\" Helper to get all the necessary data from the downloaded stuff.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir: string, \n",
    "              path to the main data dirctory\n",
    "    subject: string,\n",
    "             subject identifier\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    brain image: list of brain images for the subject\n",
    "    confound: list of confound files for the subject\n",
    "    event: list of event files for the subject\n",
    "    \"\"\"\n",
    "    # prepare the data for the subject\n",
    "    bold = []\n",
    "    confounds = []\n",
    "    events = []\n",
    "    # infer the session name for the data\n",
    "    session = [os.path.basename(x) for x in glob.glob(os.path.join(data_dir, subject, 'ses-*'))\n",
    "               if 'ses-00' not in x][0]\n",
    "    func_dir = os.path.join(data_dir, subject, session, 'func')\n",
    "    for direction in ['pa', 'ap']: # ap and pa correspond to 2 runs\n",
    "        # fMRI data\n",
    "        wc = os.path.join(\n",
    "            func_dir,\n",
    "            '{}_{}_task-MCSE_dir-{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'.format(\n",
    "                subject, session, direction))\n",
    "        bold.append(wc)\n",
    "        # associated confound data (motion, componcor output)\n",
    "        wc = os.path.join(\n",
    "            func_dir,\n",
    "            '{}_{}_task-MCSE_dir-{}_desc-confounds_timeseries.tsv'.format(\n",
    "                subject, session, direction))\n",
    "        confounds.append(wc)\n",
    "        # associated event descriptors\n",
    "        wc = os.path.join(func_dir,\n",
    "            '{}_{}_task-MCSE_dir-{}_events.tsv'.format(subject, session, direction))\n",
    "        events.append(wc)\n",
    "    return bold, confounds, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the data for one subject\n",
    "subject = subjects[0]\n",
    "bold, confounds, events = fetch_data(data_dir, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explore the experimental design of the experiment\n",
    "import pandas as pd\n",
    "from nilearn.plotting import plot_event, show\n",
    "event_dfs = [pd.read_csv(event, sep='\\t') for event in events]\n",
    "plot_event(event_dfs, figsize=(9, 4))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are 5 types of events: low and high salience stimuli, presented either on the left or right side of the display.\n",
    "There is also a dummy BFix condition (\"fixation\"), that is of no interest and actually corresponds to a baeline. We may want to get rid of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# GLM specification: specify repetition time, brain mask, spatial and temporal filtering parameters\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "model = FirstLevelModel(\n",
    "    t_r=TR, \n",
    "    mask_img=gm_mask,\n",
    "    smoothing_fwhm=5,\n",
    "    high_pass = 0.008,\n",
    "    hrf_model='spm + derivative',\n",
    "    slice_time_ref=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# utility function to specify contrasts\n",
    "def mcse_contrasts():\n",
    "    \"\"\"Specification of relevant MCSE contrasts\"\"\"\n",
    "    # to make matters simple, we specify only two contrasts\n",
    "    contrasts = {\n",
    "        'low-high salience': 'low_salience_left + low_salience_right' +\\\n",
    "            '- hi_salience_left - hi_salience_right',\n",
    "        'salience_left-right': 'low_salience_left - low_salience_right' +\\\n",
    "            '+ hi_salience_left - hi_salience_right'\n",
    "    }\n",
    "    return contrasts\n",
    "\n",
    "contrasts = mcse_contrasts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run the analysis in one subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare write dir\n",
    "subject_dir = os.path.join(write_dir, subject)\n",
    "if not os.path.exists(subject_dir):\n",
    "    os.mkdir(subject_dir)\n",
    "    \n",
    "event_dfs = []\n",
    "# loop on the two acquisitions for this subject\n",
    "for i, (event, confound, img) in enumerate(zip(events, confounds, bold)):\n",
    "    # Slightly modify the event files not to model implicit baseline, called \"Bfix\"\n",
    "    event_df = pd.read_csv(event, index_col=None, sep='\\t')\n",
    "    event_df = event_df[event_df. trial_type != 'Bfix']\n",
    "    event_dfs.append(event_df) \n",
    "\n",
    "    # fit the model\n",
    "    model.fit(img, events=event_df, confounds=confound)\n",
    "    # write the output as a report (HTML page)\n",
    "    report = model.generate_report(contrasts)\n",
    "    report.save_as_html(\n",
    "        os.path.join(subject_dir, 'report_{}.html'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just take a look at the events that were actually used\n",
    "plot_event(event_dfs, figsize=(9, 4))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "OK, but we need to have one stat map that summarizes the effects per subject. To achieve this, directly compute a fixed effects model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for this, provide list of fMRI data, events and confound descriptors\n",
    "# the report displays the fixed effects for the specified contrasts\n",
    "model.fit(bold, events=event_dfs, confounds=confounds)\n",
    "report = model.generate_report(contrasts)\n",
    "# the report can be written on disk, or displayed, or both !\n",
    "report.save_as_html(os.path.join(subject_dir, 'report_ffx.html'))\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Save contrast images to disk for future use in group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for  key in contrasts.keys():\n",
    "    stat_img = model.compute_contrast(contrasts[key], output_type='z_score')\n",
    "    output_file = os.path.join(subject_dir, f'{key}_z_score.nii.gz')\n",
    "    stat_img.to_filename(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Great, we did it on one subject. Let's write a loop to run all that stuff on all subjects of the study. We just do the minimal thing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    subject_dir = os.path.join(write_dir, subject)\n",
    "    if not os.path.exists(subject_dir):\n",
    "        os.mkdir(subject_dir)\n",
    "    \n",
    "    bold, confounds, events = fetch_data(data_dir, subject)\n",
    "    event_dfs = []\n",
    "    for event in events:\n",
    "        event_df = pd.read_csv(event, index_col=None, sep='\\t')\n",
    "        event_dfs.append(event_df[event_df. trial_type != 'Bfix'])\n",
    "    \n",
    "    model.fit(bold, events=event_dfs, confounds=confounds)\n",
    "    for  key in contrasts.keys():\n",
    "        stat_img = model.compute_contrast(\n",
    "                contrasts[key], output_type='z_score')\n",
    "        output_file = os.path.join(subject_dir, f'{key}_z_score.nii.gz')\n",
    "        stat_img.to_filename(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Do a one-sample test across subjects to discover which brain regions display a positive effect across individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "# we create a trivial design matrix with only an intercept\n",
    "# since we only study the average effect of the contrast across subjects\n",
    "design_matrix = pd.DataFrame([1] * len(subjects), columns=['intercept'])\n",
    "second_level_model = SecondLevelModel(mask_img=gm_mask)\n",
    "alpha = .05 # desired significance level for FDR control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.plotting import view_img\n",
    "views = {}\n",
    "for key in contrasts.keys():\n",
    "    # Get the images\n",
    "    imgs = [os.path.join(write_dir, subject, f'{key}_z_score.nii.gz')\n",
    "            for subject in subjects]    \n",
    "    second_level_model.fit(imgs, design_matrix=design_matrix)\n",
    "    z_map = second_level_model.compute_contrast(output_type='stat')\n",
    "    \n",
    "    # Take a statistical threshold, corresponding to fdr <= alpha\n",
    "    _, threshold = threshold_stats_img(\n",
    "        z_map, alpha=alpha, height_control='fdr')\n",
    "    print(key, threshold)\n",
    "    \n",
    "    # look at the result\n",
    "    views[key] = view_img(\n",
    "        z_map, threshold=threshold, title=f'{key}, fdr <{alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "views['salience_left-right']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mostly see differences in the early (retinotopic) cortex, where subjects were looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "views['low-high salience']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the effect of salience on brain activity across participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the map for the 'low-high salience' contrast\n",
    "key = 'low-high salience'\n",
    "imgs = [os.path.join(write_dir, subject, f'{key}_z_score.nii.gz')\n",
    "            for subject in subjects]\n",
    "second_level_model.fit(imgs, design_matrix=design_matrix)\n",
    "filename = os.path.join(write_dir, f'group_{key}_z_score.nii.gz')\n",
    "second_level_model.compute_contrast(output_type='stat').to_filename(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
