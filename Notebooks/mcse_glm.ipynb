{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running GLM for MCSE task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This script runs a simple glm on one subject for the MCSE condition\n",
    "and returns the contrasts obtained.\n",
    "Then it applies the same thing to all subjects, and eventually performs a one-sample test to detect effects at the population level.\n",
    "\n",
    "This task (described in [https://doi.org/10.1523/JNEUROSCI.6048-11.2012]) was originally used to study whether visual search processes of a salient target can be thought as a purely bottom-up process, or if it requires action from top-down attentional processes.\n",
    "\n",
    "The task consisted in the presentation of an array of 35 “L” letters, rotated at different angles, together with a target “T” letter (total 36 stimuli in each trial). Subjects were instructed to search for the target and indicate whether it was on the left or right side of the grid, by pressing respectively with the index or middle finger on a 5-button response box. There were two conditions: high-salience (the target is gray while the other stimuli is black) and low-salience (all stimuli are gray).\n",
    "\n",
    "The two conditions were presented alternatively in blocks, with 6 blocks of 10 trials\n",
    "each. Each trial was presented for 3 s with an inter-stimulus interval of 1 s. There was\n",
    "also a 20 s fixation cross between blocks. Data were acquired in two separated runs, one in the \"Posterior to Anterior\" (PA) phase encoding direction, one in the \"Anterior to Posterior\" phase encoding direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent / \"scripts\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data and understand them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is a grey matter mask, that defines which regions of the brain \n",
    "from nilearn.plotting import plot_roi\n",
    "gm_mask = 'data/gm_mask_3mm.nii.gz'\n",
    "plot_roi(gm_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This will download the data or locate it if already downloaded\n",
    "from download_data import download_data\n",
    "import os\n",
    "download_data()\n",
    "data_dir = 'data/3mm'\n",
    "subjects = [os.path.basename(x) for x in\n",
    "            glob.glob(os.path.join(data_dir, 'sub-*'))]\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Time of repetition, i.e. time between consecutive scans (in seconds)\n",
    "import json\n",
    "TR = json.load(open('data/3mm/task-MCSE_dir-ap_bold.json'))['RepetitionTime']\n",
    "print(TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a results directory, where we will generate all ouputs for this session\n",
    "# Can be any valid path on disk\n",
    "write_dir = 'results'\n",
    "if not os.path.exists(write_dir):\n",
    "    os.mkdir(write_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we define a utility function to fetch individual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_data(data_dir, subject):\n",
    "    \"\"\"Helper to get all the necessary data from the downloaded material.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir: string,\n",
    "              Path to the main data dirctory\n",
    "              \n",
    "    subject: string,\n",
    "             Subject identifier\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    brain image: list of strings,\n",
    "                 4D brain images for the subject\n",
    "                 \n",
    "    confound: list os strings,\n",
    "              Confound files for the subject\n",
    "              \n",
    "    event: list of strings,\n",
    "           List of event files for the subject\n",
    "    \"\"\"\n",
    "    # prepare the data for the subject\n",
    "    bold = []\n",
    "    confounds = []\n",
    "    events = []\n",
    "    # infer the session name for the data; \n",
    "    # we explicitly don't want to take the session names 'ses-00'\n",
    "    session = [os.path.basename(x) for x in glob.glob(\n",
    "        os.path.join(data_dir, subject, 'ses-*')) if 'ses-00' not in x][0]\n",
    "    func_dir = os.path.join(data_dir, subject, session, 'func')\n",
    "    for direction in ['pa', 'ap']: # 'pa' and 'ap'  correspond to 2 runs\n",
    "        # fMRI data\n",
    "        wc = os.path.join(\n",
    "            func_dir,\n",
    "            '{}_{}_task-MCSE_dir-{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'.format(\n",
    "                subject, session, direction))\n",
    "        bold.append(wc)\n",
    "        # associated confound data (motion, CompCor output)\n",
    "        wc = os.path.join(\n",
    "            func_dir,\n",
    "            '{}_{}_task-MCSE_dir-{}_desc-confounds_timeseries.tsv'.format(\n",
    "                subject, session, direction))\n",
    "        confounds.append(wc)\n",
    "        # associated event descriptors\n",
    "        wc = os.path.join(func_dir,\n",
    "            '{}_{}_task-MCSE_dir-{}_events.tsv'.format(subject, session, direction))\n",
    "        events.append(wc)\n",
    "    return bold, confounds, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the data for one subject\n",
    "subject = subjects[0]\n",
    "bold, confounds, events = fetch_data(data_dir, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explore the experimental design of the experiment\n",
    "import pandas as pd\n",
    "from nilearn.plotting import plot_event, show\n",
    "event_dfs = [pd.read_csv(event, sep='\\t') for event in events]\n",
    "plot_event(event_dfs, figsize=(9, 4))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are 5 types of events: low and high salience stimuli, presented either on the left or right side of the display.\n",
    "There is also a dummy BFix condition (\"fixation\"), that is of no interest and actually corresponds to a baseline. We may want to get rid of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# GLM specification: specify repetition time, brain mask, \n",
    "# spatial and temporal filtering parameters\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "model = FirstLevelModel(\n",
    "    t_r=TR,            # provide repetition time\n",
    "    mask_img=gm_mask,  # restrict analysis to grey matter regions \n",
    "    smoothing_fwhm=5,  # in mm\n",
    "    high_pass = 0.008, # in hz\n",
    "    hrf_model='spm + derivative', # hemodynamic model to use: SPM model and its time derivative\n",
    "    slice_time_ref=.5  # The design will be sampled at the middle of each volume acquisition\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# utility function to specify contrasts\n",
    "def mcse_contrasts():\n",
    "    \"\"\"Specification of relevant MCSE contrasts\"\"\"\n",
    "    # to make matters simple, we specify only two contrasts\n",
    "    # 'low-high salience' addresses the difference in brain activity btw the low and high salience condition. \n",
    "    # Obviously, low salience involves higher spatial attention, all other things being equal.\n",
    "    # salience_left-right' considers whether the target is on the left or right side of the display\n",
    "    contrasts = {\n",
    "        'low-high salience': 'low_salience_left + low_salience_right' +\\\n",
    "            '- hi_salience_left - hi_salience_right',\n",
    "        'salience_left-right': 'low_salience_left - low_salience_right' +\\\n",
    "            '+ hi_salience_left - hi_salience_right'\n",
    "    }\n",
    "    return contrasts\n",
    "\n",
    "contrasts = mcse_contrasts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run the analysis in one subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare write dir\n",
    "subject_dir = os.path.join(write_dir, subject)\n",
    "if not os.path.exists(subject_dir):\n",
    "    os.mkdir(subject_dir)\n",
    "    \n",
    "event_dfs = []\n",
    "# loop on the two acquisitions for this subject\n",
    "for i, (event, confound, img) in enumerate(zip(events, confounds, bold)):\n",
    "    # Slightly modify the event files not to model implicit baseline, called \"Bfix\"\n",
    "    event_df = pd.read_csv(event, index_col=None, sep='\\t')\n",
    "    event_df = event_df[event_df. trial_type != 'Bfix']\n",
    "    event_dfs.append(event_df) \n",
    "\n",
    "    # fit the model\n",
    "    model.fit(img, events=event_df, confounds=confound)\n",
    "    # write the output as a report (HTML page)\n",
    "    report = model.generate_report(contrasts)\n",
    "    report.save_as_html(\n",
    "        os.path.join(subject_dir, 'report_{}.html'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just take a look at the events that were actually used\n",
    "plot_event(event_dfs, figsize=(9, 4))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "OK, but we need to have one stat map that summarizes the effects per subject. To achieve this, directly compute a fixed effects model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for this, provide list of fMRI data, events and confound descriptors\n",
    "# the report displays the fixed effects for the specified contrasts\n",
    "model.fit(bold, events=event_dfs, confounds=confounds)\n",
    "report = model.generate_report(contrasts)\n",
    "# the report can be written on disk, or displayed, or both !\n",
    "report.save_as_html(os.path.join(subject_dir, 'report_ffx.html'))\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Save contrast images to disk for future use in group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for  key in contrasts.keys():\n",
    "    stat_img = model.compute_contrast(contrasts[key], output_type='z_score')\n",
    "    output_file = os.path.join(subject_dir, f'{key}_z_score.nii.gz')\n",
    "    stat_img.to_filename(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run the analysis on all subjects\n",
    "\n",
    "Great, we did it on one subject. Let's write a loop to run all that stuff on all subjects of the study. We just do the minimal thing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    subject_dir = os.path.join(write_dir, subject)\n",
    "    if not os.path.exists(subject_dir):\n",
    "        os.mkdir(subject_dir)\n",
    "    \n",
    "    bold, confounds, events = fetch_data(data_dir, subject)\n",
    "    event_dfs = []\n",
    "    for event in events:\n",
    "        event_df = pd.read_csv(event, index_col=None, sep='\\t')\n",
    "        event_dfs.append(event_df[event_df. trial_type != 'Bfix'])\n",
    "    \n",
    "    model.fit(bold, events=event_dfs, confounds=confounds)\n",
    "    for  key in contrasts.keys():\n",
    "        stat_img = model.compute_contrast(\n",
    "                contrasts[key], output_type='z_score')\n",
    "        output_file = os.path.join(subject_dir, f'{key}_z_score.nii.gz')\n",
    "        stat_img.to_filename(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Group analysis (one-sample test)\n",
    "\n",
    "Do a one-sample test across subjects to discover which brain regions display a positive effect across individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "# we create a trivial design matrix with only an intercept\n",
    "# since we only study the average effect of the contrast across subjects\n",
    "design_matrix = pd.DataFrame([1] * len(subjects), columns=['intercept'])\n",
    "second_level_model = SecondLevelModel(mask_img=gm_mask)\n",
    "alpha = .05 # desired significance level for FDR control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.plotting import view_img\n",
    "views = {}\n",
    "for key in contrasts.keys():\n",
    "    # Get the images\n",
    "    imgs = [os.path.join(write_dir, subject, f'{key}_z_score.nii.gz')\n",
    "            for subject in subjects]    \n",
    "    second_level_model.fit(imgs, design_matrix=design_matrix)\n",
    "    z_map = second_level_model.compute_contrast(output_type='stat')\n",
    "    \n",
    "    # Take a statistical threshold, corresponding to fdr <= alpha\n",
    "    _, threshold = threshold_stats_img(\n",
    "        z_map, alpha=alpha, height_control='fdr')\n",
    "    print(key, threshold)\n",
    "    \n",
    "    # look at the result\n",
    "    views[key] = view_img(\n",
    "        z_map, threshold=threshold, title=f'{key}, fdr <{alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "views['salience_left-right']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mostly see differences in the early (retinotopic) cortex, where subjects were looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "views['low-high salience']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the effect of salience on brain activity across participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the map for the 'low-high salience' contrast\n",
    "key = 'low-high salience'\n",
    "imgs = [os.path.join(write_dir, subject, f'{key}_z_score.nii.gz')\n",
    "            for subject in subjects]\n",
    "second_level_model.fit(imgs, design_matrix=design_matrix)\n",
    "filename = os.path.join(write_dir, f'group_{key}_z_score.nii.gz')\n",
    "second_level_model.compute_contrast(output_type='stat').to_filename(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
